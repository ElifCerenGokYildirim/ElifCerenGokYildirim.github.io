<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Repeated Augmented Rehearsal: A Simple but Strong Baseline for Online CL</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background-color: #f4f4f4;
            color: #333;
        }

        .container {
            max-width: 800px;
            margin: 20px auto;
            padding: 20px;
            background-color: #fff;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
            border-radius: 5px;
        }

        h1 {
            font-size: 30px;
            margin-top: 0;
            text-align: center;
            padding: 20px 0;
            background-color: #e30613;
            color: #bcbcbc;
            border-radius: 5px;
        }

        h1 a {
            color: inherit;
            text-decoration: none;
        }

        h1 a:hover {
            text-decoration: underline;
        }

        h2 {
            font-size: 24px;
            margin-top: 30px;
            color: #555;
        }

        h3 {
            font-size: 20px;
            margin-top: 20px;
            color: #777;
        }

        img {
            max-width: 100%;
            height: auto;
            margin-top: 15px;
            margin-bottom: 15px;
            border-radius: 5px;
            box-shadow: 0 0 5px rgba(0, 0, 0, 0.1);
        }

        ul {
            margin-top: 10px;
            margin-bottom: 10px;
            padding-left: 20px;
        }

        p {
            margin-top: 10px;
            margin-bottom: 10px;
            color: #444;
        }

        a {
            color: #007bff;
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        .author-section {
            display: flex;
            flex-wrap: wrap;
            align-items: center;
        }

        .author-section h3 {
            margin-right: 5px;
            font-size: 18px;
        }

        .author-section p {
            margin: 0;
            font-size: 12px;
        }

        .author-section p:not(:last-child)::after {
            content: " ";
            margin-right: 5px;
        }
    </style>
</head>
<body>

    <div class="container">
        <h1><a href="#">REPEATED AUGMENTED REHEARSAL: A SIMPLE BUT STRONG BASELINE FOR ONLINE CL</a></h1>

        <div class="author-section">
            <h3>Authors:</h3>
            <p><strong>Yaqian Zhang</strong>,</p>
            <p><strong>Bernhard Pfahringer</strong>,</p>
            <p><strong>Eibe Frank</strong>,</p>
            <p><strong>Albert Bifet</strong>,</p>
            <p><strong>Nick Jin Sean Lim</strong>,</p>
            <p><strong>Yunzhe Jia</strong></p>
        </div>

        <article class="blog-post">
            <h2>Problem Statement:</h2>
            <ul>
                <li>Memory samples often provide a poor approximation of the loss landscape of past tasks, especially near a high-loss ridge.</li>
            </ul>

            <h2>Research Goals:</h2>
            <ul>
                <li>Instead of ending up near a high-loss ridge, the method aims to end up <em>on</em> the high-loss ridge.</li>
                <li>Mitigate overfitting to the memory buffer and ensure memory samples approximate the distribution of all past data more effectively.</li>
            </ul>

            <h2>Proposed Approach:</h2>
            <ul>
                <li><strong>Repeated Rehearsal:</strong> Perform multiple gradient-update <strong>iterations (K)</strong> per incoming batch to reduce underfitting. This can be plugged into existing Experience Replay (ER) variants.</li>
                <li><strong>Data Augmentation:</strong> Apply random transformations (e.g., RandAugment with parameters <em>P</em>, <em>Q</em>) to both incoming and memory batches at each iteration. This regularizes new data and diversifies the memory distribution.</li>
            </ul>

            <h2>Adaptive Hyperparameter Tuning:</h2>
            <p>Use a <strong>reinforcement learning</strong> agent (bootstrapped policy gradient) to dynamically tune:</p>
            <ul>
                <li>Number of iterations <strong>K</strong></li>
                <li>Augmentation strength <strong>(P, Q)</strong></li>
                <li>Guided by memory-batch accuracy to detect and respond to overfitting risk</li>
            </ul>

            <h2>Experimental Setup:</h2>
            <ul>
                <li><strong>Datasets:</strong> Seq-CIFAR100 (20 tasks), Seq-MiniImageNet (10 tasks), CORE50-NC (9 tasks), CLRS25-NC (5 tasks)</li>
                <li><strong>Memory Sizes:</strong> 2,000 and 5,000 samples</li>
                <li><strong>Training Setup:</strong> Standard online continual learning configuration</li>
            </ul>

            <h2>Results:</h2>
            <img src="/blog/simple_but_strong_baseline_online_cl/result_table.jpg" alt="Results">

            <h2>Limitations:</h2>
            <ul>
                <li>Hyperparameter tuning depends on external validation data â€” a limitation also shared by other works like AdaCL.</li>
            </ul>

            <h2>Strengths:</h2>
            <ul>
                <li>A simple yet effective plug-in strategy.</li>
                <li>Improves generalization by diversifying memory and tuning training dynamics adaptively.</li>
            </ul>

            <h2>Future Work:</h2>
            <ul>
                <li>Apply the method beyond image classification, potentially exploring NLP or multimodal tasks.</li>
            </ul>
        </article>
    </div>
</body>
</html>

