
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Exploring Example Influence in CL</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background-color: #f4f4f4;
            color: #333;
        }

        .container {
            max-width: 800px;
            margin: 20px auto;
            padding: 20px;
            background-color: #fff;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
            border-radius: 5px;
        }

        h1 {
            font-size: 30px;
            margin-top: 0;
            text-align: center;
            padding: 20px 0;
            background-color: #ff4794;
            color: #fef2ee;
            border-radius: 5px;
        }

        h1 a {
            color: inherit;
            text-decoration: none;
        }

        h1 a:hover {
            text-decoration: underline;
        }

        h2 {
            font-size: 24px;
            margin-top: 30px;
            color: #555;
        }

        h3 {
            font-size: 20px;
            margin-top: 20px;
            color: #777;
        }

        img {
            max-width: 100%;
            height: auto;
            margin-top: 15px;
            margin-bottom: 15px;
            border-radius: 5px;
            box-shadow: 0 0 5px rgba(0, 0, 0, 0.1);
        }

        ul {
            margin-top: 10px;
            margin-bottom: 10px;
            padding-left: 20px;
        }

        p {
            margin-top: 10px;
            margin-bottom: 10px;
            color: #444;
        }

        a {
            color: #007bff;
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        .author-section {
            display: flex;
            flex-wrap: wrap;
            align-items: center;
        }

        .author-section h3 {
            margin-right: 5px;
            font-size: 18px;
        }

        .author-section p {
            margin: 0;
            font-size: 12px;
        }

        .author-section p:not(:last-child)::after {
            content: " ";
            margin-right: 5px;
        }
    </style>
</head>
<body>

    <div class="container">
        <h1><a href="#">EXPLORING EXAMPLE INFLUENCE IN CL</a></h1>

        <div class="author-section">
            <h3>Authors:</h3>
            <p><strong>Qing Sun&#42;</strong>,</p>
            <p><strong>Fan Lyu&#42;</strong>,</p>
            <p><strong>Fanhua Shang</strong>,</p>
            <p><strong>Wei Feng</strong>,</p>
            <p><strong>Liang Wan&#8224;</strong></p>
        </div>

        <article class="blog-post">
            <h2>Problem Statement:</h2>
            <ul>
                <li>To understand example influence, one classic technique is the Influence Function (IF), which leverages the chain rule from a test objective to training examples. However, directly applying it leads to high computational complexity.</li>
            </ul>

            <h2>Research Goals:</h2>
            <ul>
                <li>Explore a reasonable influence from each training example to Stability (S) and Plasticity (P), and apply example influence to continual learning training.</li>
                <li>Propose a meta‑learning algorithm, <strong>MetaSP</strong>, to simulate IF and avoid expensive chain‑rule calculations.</li>
            </ul>

            <h2>Proposed Approach:</h2>
            <ul>
                <li>Hold a pseudo‑update with per‑example perturbations, then use two small validation sets (from old and new data) to compute gradients on those perturbations—these gradients estimate the example’s influence on S and P.</li>
                  <img src="/blog/exploring_example_influence/eq1.jpg" alt="Results" >
                <li>Fuse S‑ and P‑influences via a Pareto‑optimal mixing weight γ using MGDA, yielding a influence vector I*.</li>
                  <img src="/blog/exploring_example_influence/eq2.jpg" alt="Results">
              <li>Use I* to regularize model updates (upweight helpful examples, downweight harmful ones) and to rank examples for rehearsal buffer selection.</li>
                  <img src="/blog/exploring_example_influence/eq3.jpg" alt="Results">
            </ul>

            <img src="/blog/exploring_example_influence/teaser.jpg" alt="Results"  >
            <h2>Summarized Steps:</h2>
            <h3>Pseudo‑Update Simulation</h3>
            <ul>
                <li>From current parameters θ, perform a one‑step “virtual” update adding small per‑example perturbation E to the batch loss.</li>
            </ul>
            <h3>Compute S‑ and P‑Aware Influences</h3>
            <ul>
                <li>Measure how the pseudo‑update changes losses on two validation sets (<strong>V<sub>old</sub></strong> and <strong>V<sub>new</sub></strong>), and take gradients w.r.t. E.</li>
            </ul>
            <h3>SP Fusion via Pareto Optimality</h3>
            <ul>
                <li>Solve a two‑objective optimization for γ via MGDA to combine S‑ and P‑gradients into I*.</li>
            </ul>
            <h3>Leveraging Influences</h3>
            <ul>
                <li><strong>Model Update:</strong> Regularize SGD by subtracting I* &gt;L.</li>
                <li><strong>Rehearsal Selection:</strong> Rank examples by I* and store the top ones, dropping the least helpful.</li>
            </ul>

            <h2>Experimental Setup:</h2>
            <ul>
                <li><strong>Benchmarks:</strong> Split‑CIFAR‑10, Split‑CIFAR‑100, Split‑Mini‑ImageNet (class‑ and task‑incremental).</li>
                <li><strong>Model:</strong> ResNet‑18 from scratch; replay batch size 32; use 10% of buffer & seen data as V<sub>old</sub>/V<sub>new</sub>.</li>
                <li><strong>Training:</strong> 50 epochs per task; varied replay memory sizes.</li>
            </ul>

            <h2>Results:</h2>
            <img src="/blog/exploring_example_influence/result_table.jpg" alt="Results"  >

            <h2>Limitations:</h2>
            <ul>
                <li>Relies on a replay buffer, which may not suit privacy‑sensitive or zero‑memory settings.</li>
                <li>Pseudo‑update and dual validation add extra compute overhead.</li>
            </ul>

            <h2>Strengths:</h2>
            <ol>
                <li><strong>Efficiency:</strong> Simulates IFs with first‑order gradients—no Hessian inversions—scalable to deep nets.</li>
                <li><strong>Principled Fusion:</strong> Uses multi‑objective optimization to balance remembering old tasks and adapting to new ones.</li>
            </ol>

            <h2>Future Work:</h2>
            <ul>
                <li>Explore lighter‑weight validation schemes or proxy metrics to reduce compute overhead.</li>
            </ul>
        </article>
    </div>
</body>
</html>
